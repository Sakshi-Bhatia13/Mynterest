{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8952389,"sourceType":"datasetVersion","datasetId":5387658}],"dockerImageVersionId":30096,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine Tune ","metadata":{}},{"cell_type":"markdown","source":"## Step 1. Data preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport json\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:50:42.414975Z","iopub.execute_input":"2024-07-14T19:50:42.415331Z","iopub.status.idle":"2024-07-14T19:50:42.520032Z","shell.execute_reply.started":"2024-07-14T19:50:42.415300Z","shell.execute_reply":"2024-07-14T19:50:42.519301Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def cleaning(s):\n    s = str(s)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\"co\",\"\")\n    s = s.replace(\"https\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:37:21.035191Z","iopub.execute_input":"2024-07-14T19:37:21.035515Z","iopub.status.idle":"2024-07-14T19:37:21.041552Z","shell.execute_reply.started":"2024-07-14T19:37:21.035486Z","shell.execute_reply":"2024-07-14T19:37:21.040730Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/outfit-descriptions/captions.json', 'r') as file:\n    data = json.load(file)\n\ndf = pd.DataFrame(list(data.items()), columns=['Image', 'Description'])\n\ndf = df.drop(columns=['Image'])\ntext_data = open('Descriptions.txt', 'w')\nfor idx, item in df.iterrows():\n  article = cleaning(item[\"Description\"])\n  text_data.write(article)\ntext_data.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:37:21.045253Z","iopub.execute_input":"2024-07-14T19:37:21.045579Z","iopub.status.idle":"2024-07-14T19:37:27.126520Z","shell.execute_reply.started":"2024-07-14T19:37:21.045550Z","shell.execute_reply":"2024-07-14T19:37:27.125369Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Model Training","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:50:54.726901Z","iopub.execute_input":"2024-07-14T19:50:54.727326Z","iopub.status.idle":"2024-07-14T19:51:02.924855Z","shell.execute_reply.started":"2024-07-14T19:50:54.727285Z","shell.execute_reply":"2024-07-14T19:51:02.923699Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.59.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.3.17)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TextDataset, DataCollatorForLanguageModeling\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:51:02.926867Z","iopub.execute_input":"2024-07-14T19:51:02.927251Z","iopub.status.idle":"2024-07-14T19:51:02.932676Z","shell.execute_reply.started":"2024-07-14T19:51:02.927196Z","shell.execute_reply":"2024-07-14T19:51:02.931545Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def load_dataset(file_path, tokenizer, block_size = 128):\n    dataset = TextDataset(\n        tokenizer = tokenizer,\n        file_path = file_path,\n        block_size = block_size,\n    )\n    return dataset\n\n\ndef load_data_collator(tokenizer, mlm = False):\n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, \n        mlm=mlm,\n    )\n    return data_collator\n\n\ndef train(train_file_path,model_name,\n          output_dir,\n          overwrite_output_dir,\n          per_device_train_batch_size,\n          num_train_epochs,\n          save_steps):\n  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n  train_dataset = load_dataset(train_file_path, tokenizer)\n  data_collator = load_data_collator(tokenizer)\n\n  tokenizer.save_pretrained(output_dir)\n      \n  model = GPT2LMHeadModel.from_pretrained(model_name)\n\n  model.save_pretrained(output_dir)\n\n  training_args = TrainingArguments(\n          output_dir=output_dir,\n          overwrite_output_dir=overwrite_output_dir,\n          per_device_train_batch_size=per_device_train_batch_size,\n          num_train_epochs=num_train_epochs,\n      )\n\n  trainer = Trainer(\n          model=model,\n          args=training_args,\n          data_collator=data_collator,\n          train_dataset=train_dataset,\n  )\n      \n  trainer.train()\n  trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:51:02.934670Z","iopub.execute_input":"2024-07-14T19:51:02.935041Z","iopub.status.idle":"2024-07-14T19:51:02.944735Z","shell.execute_reply.started":"2024-07-14T19:51:02.935003Z","shell.execute_reply":"2024-07-14T19:51:02.943833Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# you need to set parameters \ntrain_file_path = \"/kaggle/working/Descriptions.txt\"\nmodel_name = 'gpt2'\noutput_dir = '/kaggle/working/result'\noverwrite_output_dir = False\nper_device_train_batch_size = 8\nnum_train_epochs = 5.0\nsave_steps = 500","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:51:17.661615Z","iopub.execute_input":"2024-07-14T19:51:17.661974Z","iopub.status.idle":"2024-07-14T19:51:17.667210Z","shell.execute_reply.started":"2024-07-14T19:51:17.661944Z","shell.execute_reply":"2024-07-14T19:51:17.666384Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# It takes about 30 minutes to train in colab.\ntrain(\n    train_file_path=train_file_path,\n    model_name=model_name,\n    output_dir=output_dir,\n    overwrite_output_dir=overwrite_output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    num_train_epochs=num_train_epochs,\n    save_steps=save_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:51:19.297162Z","iopub.execute_input":"2024-07-14T19:51:19.297509Z","iopub.status.idle":"2024-07-14T20:34:11.382262Z","shell.execute_reply.started":"2024-07-14T19:51:19.297479Z","shell.execute_reply":"2024-07-14T20:34:11.381279Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f895b755fb4377b3c3bf6846bf8abf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27fc084c05d34e28ac111955c5ffd858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ded71d1c686468aafe4e0baea77e3ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1d5859b05e4687b899a678411030e9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b13e096cd8e4651978ebc49cf37a5bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79749420dd9149658bd81d26c85e17e7"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.4 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.26<br/>\n                Syncing run <strong style=\"color:#cdcd00\">/kaggle/working/result</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/vanib31415-abv-iiitm-gwalior/huggingface\" target=\"_blank\">https://wandb.ai/vanib31415-abv-iiitm-gwalior/huggingface</a><br/>\n                Run page: <a href=\"https://wandb.ai/vanib31415-abv-iiitm-gwalior/huggingface/runs/3lx8g02b\" target=\"_blank\">https://wandb.ai/vanib31415-abv-iiitm-gwalior/huggingface/runs/3lx8g02b</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20240714_195336-3lx8g02b</code><br/><br/>\n            "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='5365' max='5365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5365/5365 40:24, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.536300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.414200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.397400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.389500</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.381600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.377100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.375000</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.370900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.368800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.367000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 3. Inference","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Assuming `tokenizer` is your tokenizer\ntokenizer_path = \"/kaggle/working/tokenizer\"\ntokenizer.save_pretrained(tokenizer_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:26:43.246087Z","iopub.execute_input":"2024-07-14T21:26:43.246443Z","iopub.status.idle":"2024-07-14T21:26:43.277621Z","shell.execute_reply.started":"2024-07-14T21:26:43.246404Z","shell.execute_reply":"2024-07-14T21:26:43.276279Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-94c7c2f8780d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming `tokenizer` is your tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/working/tokenizer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model_path = \"/kaggle/working/result\"\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\nmodel.save_pretrained(output_dir)\n# tokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T20:52:48.235131Z","iopub.execute_input":"2024-07-14T20:52:48.235633Z","iopub.status.idle":"2024-07-14T20:52:54.065695Z","shell.execute_reply.started":"2024-07-14T20:52:48.235592Z","shell.execute_reply":"2024-07-14T20:52:54.064751Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-07-14T20:53:23.638591Z","iopub.execute_input":"2024-07-14T20:53:23.638944Z","iopub.status.idle":"2024-07-14T20:53:23.644865Z","shell.execute_reply.started":"2024-07-14T20:53:23.638913Z","shell.execute_reply":"2024-07-14T20:53:23.643802Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def load_model(model_path):\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n    return model\n\n\ndef load_tokenizer(tokenizer_path):\n    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n    return tokenizer\n\n\ndef generate_text(sequence, max_length, n):\n    from transformers import AutoModelForCausalLM, AutoTokenizer\n    \n    model_path = \"/kaggle/working/result\"\n    model = AutoModelForCausalLM.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    prompts = []\n\n    for _ in range(n):\n        ids = tokenizer.encode(sequence, return_tensors='pt')\n        final_outputs = model.generate(\n            ids,\n            do_sample=True,\n            max_length=max_length,\n            pad_token_id=tokenizer.eos_token_id,\n            top_k=50,\n            top_p=0.95,\n            eos_token_id=tokenizer.eos_token_id  # Ensure generation stops at EOS token\n        )\n        prompt = tokenizer.decode(final_outputs[0], skip_special_tokens=True)\n        \n        # Post-processing to ensure the prompt ends with a complete sentence\n        prompt = prompt.rstrip()  # Remove any trailing whitespace\n        if not prompt.endswith(('.', '!', '?')):  # Check if the prompt doesn't end with punctuation\n            # Find the last punctuation mark to cut off the prompt at the end of the sentence\n            for punctuation in ('.', '!', '?'):\n                pos = prompt.rfind(punctuation)\n                if pos != -1:\n                    prompt = prompt[:pos+1]\n                    break\n        \n        prompts.append(prompt)\n    \n    return prompts","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:18:05.374280Z","iopub.execute_input":"2024-07-14T21:18:05.374631Z","iopub.status.idle":"2024-07-14T21:18:05.385725Z","shell.execute_reply.started":"2024-07-14T21:18:05.374600Z","shell.execute_reply":"2024-07-14T21:18:05.384634Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Example usage:\nsequence = \"Generate an outfit description based on current fashion trends:\"\nmax_length = 100\nn = 50\noutfit_descriptions = generate_text(sequence, max_length, n)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:33:22.956069Z","iopub.execute_input":"2024-07-14T21:33:22.956437Z","iopub.status.idle":"2024-07-14T21:36:22.571944Z","shell.execute_reply.started":"2024-07-14T21:33:22.956393Z","shell.execute_reply":"2024-07-14T21:36:22.570913Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(outfit_descriptions, columns=[\"Description\"])\ncsv_path = \"/kaggle/working/outfit_descriptions.csv\"\ndf.to_csv(csv_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:27:09.133654Z","iopub.execute_input":"2024-07-14T21:27:09.134005Z","iopub.status.idle":"2024-07-14T21:27:09.373059Z","shell.execute_reply.started":"2024-07-14T21:27:09.133973Z","shell.execute_reply":"2024-07-14T21:27:09.372309Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:37:10.271837Z","iopub.execute_input":"2024-07-14T21:37:10.272196Z","iopub.status.idle":"2024-07-14T21:37:10.282610Z","shell.execute_reply.started":"2024-07-14T21:37:10.272162Z","shell.execute_reply":"2024-07-14T21:37:10.281517Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                         Description\n0  Generate an outfit description based on curren...\n1  Generate an outfit description based on curren...\n2  Generate an outfit description based on curren...\n3  Generate an outfit description based on curren...\n4  Generate an outfit description based on curren...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Generate an outfit description based on curren...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate an outfit description based on curren...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Generate an outfit description based on curren...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate an outfit description based on curren...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Generate an outfit description based on curren...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}